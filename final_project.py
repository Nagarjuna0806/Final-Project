# -*- coding: utf-8 -*-
"""Final_project_redux.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tjvj4-xuKDyzmZ4_mQcRrU7bcU-tGDyg

#Utilizing Deep Learning for Enhanced Phishing Email Detection

This project compares three deep learning models for phishing detections. We will compare BiLSTM, CNN, and CNN-LSTM models. We will utilize the SpamAssassin and Nazario Phishing Corpus datasets.
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d ganiyuolalekan/spam-assassin-email-classification-dataset
!unzip spam-assassin-email-classification-dataset.zip

"""#Dataset Preprocessing"""

import numpy as np
import pandas as pd
import tensorflow as tf
import seaborn as sns
import matplotlib.pyplot as plt

from tensorflow.keras import layers, models, initializers, callbacks
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.metrics import Precision, Recall
from keras.callbacks import ModelCheckpoint, TensorBoard

from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


# Load dataset and display dataframe info
Spam_assassin_df = pd.read_csv('spam_assassin.csv')
Spam_assassin_df.info()

#examine dataframe head
Spam_assassin_df.head()

#load a local copy of Nazario phishing
files.upload()

# Load the Nazario.csv file into a pandas DataFrame
Nazario_df = pd.read_csv('Nazario.csv')

# Drop any rows with missing values
Nazario_df.dropna(inplace=True)

# Remove any duplicate rows
Nazario_df.drop_duplicates(inplace=True)

# Check for any remaining missing values
missing_values = Nazario_df.isnull().sum()

# If there are no missing values, then the file is clean
if missing_values.sum() == 0:
  print("The Nazario.csv file is clean.")
else:
  print("There are still missing values in the Nazario.csv file.")

#Examine dataframe containing Nazario phising data
Nazario_df.info()
Nazario_df.head()

"""Above we notice there appears to be some UTF-8 encoded sequences in the Nazario text. We need to clean that up as well"""

import re

# Function to clean UTF-8 encoded sequences from the text
def clean_utf8_encoded_sequences(text):
    # Remove zero-width spaces
    text = re.sub(r'\xe2\x80\x8b', '', text)

    # Remove other non-visible characters as needed
    # Remove soft hyphen
    text = re.sub(r'\xc2\xad', '', text)

    # Decode bytes to string if the text is in byte format
    if isinstance(text, bytes):
        text = text.decode('utf-8')

    return text

# Apply the cleaning function to the text column
Nazario_df['cleaned_text'] = Nazario_df['text'].apply(clean_utf8_encoded_sequences)

#print head of the dataframe
Nazario_df.head()

#Replace the text column with the cleaned text column
Nazario_df['text'] = Nazario_df['cleaned_text']
Nazario_df = Nazario_df.drop('cleaned_text', axis=1)

# Combine the SpamAssassin and Nazario dataframes and shuffle the combined dataset
combined_df = pd.concat([Nazario_df, Spam_assassin_df], ignore_index=True)
combined_df = combined_df.sample(frac=1).reset_index(drop=True)

#Examine the combined dataframe info and head of the dataframe
combined_df.info()
combined_df.head()

# Plot the class distribution of the SpamAssassin dataset
class_counts = Spam_assassin_df['target'].value_counts()

plt.figure(figsize=(8, 5))
sns.barplot(x=class_counts.index, y=class_counts.values)
plt.title('SpamAssasin Dataset Class Distribution')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.xticks(ticks=[0, 1], labels=['Non-Phishing', 'Phishing'])
plt.show()

#class distribution with the datasets combined

combined_class_counts = combined_df['target'].value_counts()

plt.figure(figsize=(8, 5))
sns.barplot(x=combined_class_counts.index, y=combined_class_counts.values)
plt.title('Combined Class Distribution')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.xticks(ticks=[0, 1], labels=['Non-Phishing', 'Phishing'])
plt.show()

# Text Vectorization
max_length = 600
max_tokens = 22000
text_vectorization = layers.TextVectorization(max_tokens=max_tokens, output_mode="int", output_sequence_length=max_length)
text_vectorization.adapt(combined_df['text'])

#function is used to prepare the dataset for training and evaluation by converting the input features (X) and labels (y) into a tf.data.Dataset object
#takes the input features (X) and labels (y), converts them into NumPy arrays, creates a tf.data.Dataset object from those arrays, applies batching and prefetching to improve performance,
#and finally applies text vectorization to preprocess the text data.

def prepare_ds(X, y):
    texts = X.to_numpy()
    labels = y.to_numpy()
    ds = tf.data.Dataset.from_tensor_slices((texts, labels))
    ds = ds.batch(32).prefetch(tf.data.AUTOTUNE)
    return ds.map(lambda x, y: (text_vectorization(x), y))

# Define the number of folds
n_splits = 5

# Initialize KFold object
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)

#defining a function for model training and evaluation

def train_and_evaluate_model(model, X, y, n_splits, callbacks=None):
    # Initialize lists to store the evaluation metrics for each fold
    accuracies = []
    precisions = []
    recalls = []
    f1_scores = []
    y_true_all = []
    y_pred_all = []

    fold = 1
    for train_index, val_index in kfold.split(X):
        print(f"Fold {fold}")

        # Split the data into training and validation sets for the current fold
        X_train, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train, y_val = y.iloc[train_index], y.iloc[val_index]

        # Prepare the datasets for training and validation
        train_ds = prepare_ds(X_train, y_train)
        val_ds = prepare_ds(X_val, y_val)

        # Train the model
        history = model.fit(train_ds, validation_data=val_ds, epochs=20, callbacks=callbacks, verbose=0)

        # Evaluate the model on the validation set
        y_pred = (model.predict(val_ds) > 0.5).astype(int)
        y_true = np.concatenate([y for x, y in val_ds], axis=0)

        y_true_all.extend(y_true)
        y_pred_all.extend(y_pred)

        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred)
        recall = recall_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred)

        accuracies.append(accuracy)
        precisions.append(precision)
        recalls.append(recall)
        f1_scores.append(f1)

        print(f"Fold {fold} - Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}")
        fold += 1

    # Calculate the mean evaluation metrics across all folds
    mean_accuracy = np.mean(accuracies)
    mean_precision = np.mean(precisions)
    mean_recall = np.mean(recalls)
    mean_f1_score = np.mean(f1_scores)

    print(f"\nMean Accuracy: {mean_accuracy:.3f}")
    print(f"Mean Precision: {mean_precision:.3f}")
    print(f"Mean Recall: {mean_recall:.3f}")
    print(f"Mean F1-score: {mean_f1_score:.3f}")

    return history, accuracies, precisions, recalls, f1_scores, y_true_all, y_pred_all

#download and unzip GloVe pretrained word embeddings
!wget http://nlp.stanford.edu/data/glove.6B.zip
!unzip glove.6B.zip

# Parsing the GloVe word-embeddings file
embedding_dim = 100
embeddings_index = {}
with open("glove.6B.100d.txt") as f:
    for line in f:
        word, coefs = line.split(maxsplit=1)
        coefs = np.fromstring(coefs, "f", sep=" ")
        embeddings_index[word] = coefs

vocabulary = text_vectorization.get_vocabulary()
word_index = dict(zip(vocabulary, range(len(vocabulary))))

#Preparing the GloVe word-embeddings matrix
embedding_matrix = np.zeros((max_tokens, embedding_dim))
for word, i in word_index.items():
    if i < max_tokens:
        embedding_vector = embeddings_index.get(word)
        if embedding_vector is not None:
            embedding_matrix[i] = embedding_vector

embedding_layer = layers.Embedding(max_tokens, embedding_dim, embeddings_initializer=initializers.Constant(embedding_matrix), trainable=False, mask_zero=True)

"""Tensorboard allows us to see realtime graphs of the data during training"""

# Commented out IPython magic to ensure Python compatibility.
#Loading tensorboard to examine realtime graphs during output
# %load_ext tensorboard
# %tensorboard --logdir /content/logs

"""#Bidirectional LSTM model"""

#Define the BiLSTM model
def create_BiLSTM_model():
	inputs = layers.Input(shape=(None,), dtype="int64")
	embedded = embedding_layer(inputs)
	x = layers.Bidirectional(layers.LSTM(32))(embedded)
	x = layers.Dropout(0.5)(x)
	outputs = layers.Dense(1, activation="sigmoid")(x)
	model = models.Model(inputs, outputs)
	return model

# Create the biLSTM model
bilstm_model = create_BiLSTM_model()

# Compile the model
bilstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])

# Print the model summary
bilstm_model.summary()

#Create an instance of the EarlyStopping callback
early_stopping = EarlyStopping(
    monitor='val_loss',  # Metric to monitor
    patience=3,  # Number of epochs to wait for improvement
    restore_best_weights=True  # Restore the best weights from the epoch with the best metric value
)

#Plot the model topology

tf.keras.utils.plot_model(bilstm_model, "bilstm_model_info.png", show_shapes=True)

#define callbacks to use
callbacks = [
    callbacks.ModelCheckpoint("Best_BiLSTM_model.tf", save_best_only=True),
    callbacks.TensorBoard(log_dir="/content/logs/bilstm"),
    early_stopping
]

# Train and evaluate the BiLSTM model using k-fold cross-validation
bilstm_history, bilstm_accuracies, bilstm_precisions, bilstm_recalls, bilstm_f1_scores, bilstm_y_true, bilstm_y_pred = train_and_evaluate_model(bilstm_model, combined_df['text'], combined_df['target'], n_splits, callbacks)

"""#CNN Model"""

# Define the CNN model
def create_CNN_model(embedding_layer, max_length):
  inputs = layers.Input(shape=(max_length,), dtype="int64")
  x = embedding_layer(inputs)
  x = layers.Conv1D(filters=128, kernel_size=5, activation='relu')(x)
  x = layers.MaxPooling1D(pool_size=2)(x)
  x = layers.Flatten()(x)
  outputs = layers.Dense(1, activation='sigmoid')(x)
  model = models.Model(inputs=inputs, outputs=outputs)
  return model

 #Create the CNN model
cnn_model = create_CNN_model(embedding_layer, max_length)

 #Compile the model
cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])

 #Print the model summary
cnn_model.summary()

#Plot the model topology

tf.keras.utils.plot_model(cnn_model, "cnn_model_info.png", show_shapes=True)

#define callbacks to use
callbacks = [
    ModelCheckpoint("Best_CNN_model.tf", save_best_only=True),
    TensorBoard(log_dir="/content/logs/cnn"),
    early_stopping
]

# Train and evaluate the CNN model using k-fold cross-validation
cnn_history, cnn_accuracies, cnn_precisions, cnn_recalls, cnn_f1_scores, cnn_y_true, cnn_y_pred = train_and_evaluate_model(cnn_model, combined_df['text'], combined_df['target'], n_splits, callbacks)

"""#CNN-LSTM Model"""

# Define the CNN-LSTM model
def create_CNN_LSTM_model(embedding_layer):
	inputs = layers.Input(shape=(max_length,))
	embedded = embedding_layer(inputs)
	x = layers.Conv1D(128, 5, activation='relu')(embedded)
	x = layers.MaxPooling1D(5)(x)
	x = layers.Conv1D(128, 5, activation='relu')(x)
	x = layers.MaxPooling1D(5)(x)
	x = layers.Conv1D(128, 5, activation='relu')(x)
	x = layers.MaxPooling1D(5)(x)
	x = layers.LSTM(128)(x)
	x = layers.Dense(128, activation='relu')(x)
	outputs = layers.Dense(1, activation='sigmoid')(x)
	model = models.Model(inputs=inputs, outputs=outputs)
	return model

 # Create the CNN-LSTM model
cnn_lstm_model = create_CNN_LSTM_model(embedding_layer)

 # Compile the model
cnn_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])

 # Print the model summary
cnn_lstm_model.summary()

#plot the model topology

tf.keras.utils.plot_model(cnn_lstm_model, "cnn_lstm_model_info.png", show_shapes=True)

#define callbacks to use
callbacks = [
    ModelCheckpoint("Best_CNN_LSTM_model.tf", save_best_only=True),
    TensorBoard(log_dir="/content/logs/cnn_lstm"),
    early_stopping
]

# Train and evaluate the CNN model using k-fold cross-validation
cnn_lstm_history, cnn_lstm_accuracies, cnn_lstm_precisions, cnn_lstm_recalls, cnn_lstm_f1_scores, cnn_lstm_y_true, cnn_lstm_y_pred = train_and_evaluate_model(cnn_lstm_model, combined_df['text'], combined_df['target'], n_splits, callbacks)

"""#Visualizations"""

# function to plot the training and validation loss
def plot_loss_curves(history, model_name):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'{model_name} - Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

# Plot the loss curves for BiLSTM model
plot_loss_curves(bilstm_history, 'BiLSTM')

# Plot the loss curves for CNN model
plot_loss_curves(cnn_history, 'CNN')

# Plot the loss curves for CNN-LSTM model
plot_loss_curves(cnn_lstm_history, 'CNN-LSTM')

#functions to plot the accuracy and F1-score bar plots
def plot_accuracy_bar(accuracies, model_names):
    plt.figure(figsize=(10, 6))
    x = np.arange(len(accuracies[0]))
    width = 0.2

    for i, accuracy in enumerate(accuracies):
        plt.bar(x + i * width, accuracy, width, label=f'{model_names[i]} Accuracy')

    plt.ylabel('Accuracy')
    plt.title('Model Accuracy Comparison')
    plt.xticks(x + width / 2, [f'Fold {i+1}' for i in range(len(accuracies[0]))])
    plt.legend(loc='lower right')
    plt.show()

def plot_f1_score_bar(f1_scores, model_names):
    plt.figure(figsize=(10, 6))
    x = np.arange(len(f1_scores[0]))
    width = 0.2

    for i, f1_score in enumerate(f1_scores):
        plt.bar(x + i * width, f1_score, width, label=f'{model_names[i]} F1-Score')

    plt.ylabel('F1-Score')
    plt.title('Model F1-Score Comparison')
    plt.xticks(x + width / 2, [f'Fold {i+1}' for i in range(len(f1_scores[0]))])
    plt.legend(loc='lower right')
    plt.show()


model_names = ['BiLSTM', 'CNN', 'CNN-LSTM']
accuracies = [bilstm_accuracies, cnn_accuracies, cnn_lstm_accuracies]
f1_scores = [bilstm_f1_scores, cnn_f1_scores, cnn_lstm_f1_scores]

#Plot the accuracy and F1-score bar plots
plot_accuracy_bar(accuracies, model_names)
plot_f1_score_bar(f1_scores, model_names)

#function to plot the confusion matrix
def plot_confusion_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=['Non-Spam', 'Spam'], yticklabels=['Non-Spam', 'Spam'])
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'Confusion Matrix - {model_name}')
    plt.show()

#Plot the confusion matrices for each model
plot_confusion_matrix(bilstm_y_true, bilstm_y_pred, 'BiLSTM')
plot_confusion_matrix(cnn_y_true, cnn_y_pred, 'CNN')
plot_confusion_matrix(cnn_lstm_y_true, cnn_lstm_y_pred, 'CNN-LSTM')